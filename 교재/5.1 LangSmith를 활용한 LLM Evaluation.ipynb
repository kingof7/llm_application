{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langsmith in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (0.3.44)\n",
      "Requirement already satisfied: openai in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (1.83.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-pinecone in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (0.2.6)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langsmith) (3.10.18)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langsmith) (24.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langsmith) (2.11.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langsmith) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langsmith) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: pinecone<7.0.0,>=6.0.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<3.11,>=3.10 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-pinecone) (3.10.11)\n",
      "Requirement already satisfied: numpy>=1.26.4 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-pinecone) (2.2.6)\n",
      "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-pinecone) (0.3.19)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.20.0)\n",
      "Requirement already satisfied: pytest<9,>=7 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (8.4.0)\n",
      "Requirement already satisfied: pytest-asyncio<1,>=0.20 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.26.0)\n",
      "Requirement already satisfied: syrupy<5,>=4 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.1)\n",
      "Requirement already satisfied: pytest-socket<1,>=0.6.0 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n",
      "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: iniconfig>=1 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.19.1)\n",
      "Requirement already satisfied: tomli>=1 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.2.1)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain-pinecone) (0.3.1)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [bs4]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 bs4-0.0.2 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langsmith openai python-dotenv langchain langchain-openai langchain-pinecone bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 생성\n",
    "\n",
    "- Evaluation에 활용될 Question - Answer pair 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Evaluation\n",
    "할루시네이션 예방\n",
    "잘못된 답변을 방지하기 위한 최소한의 도구\n",
    "LangSmith를 활용한 Evaluation\n",
    "\n",
    "## Dataset 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"up_FeRaFreJQmiZyVXY5cNGqUwWisws2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Initialize a text splitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add the document chunks to the \"vector store\" using OpenAIEmbeddings\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\"),\n",
    ")\n",
    "\n",
    "# With langchain we can easily turn any vector store into a retrieval component:\n",
    "retriever = vectorstore.as_retriever(k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langsmith import traceable\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "# Add decorator so this function is traced in LangSmith\n",
    "@traceable()\n",
    "def rag_bot(question: str) -> dict:\n",
    "    # LangChain retriever will be automatically traced\n",
    "    docs = retriever.invoke(question)\n",
    "    docs_string = \"\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    instructions = f\"\"\"You are a helpful assistant who is good at analyzing source information and answering questions.       Use the following source documents to answer the user's questions.       If you don't know the answer, just say that you don't know.       Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Documents:\n",
    "{docs_string}\"\"\"\n",
    "\n",
    "    # langchain ChatModel will be automatically traced\n",
    "    ai_msg = llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return {\"answer\": ai_msg.content, \"documents\": docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "LangSmithAuthError",
     "evalue": "Authentication failed for /datasets. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Invalid token\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/utils.py:154\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/client.py:828\u001b[0m, in \u001b[0;36mClient.request_with_retries\u001b[0;34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    823\u001b[0m         method,\n\u001b[1;32m    824\u001b[0m         _construct_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url, pathname),\n\u001b[1;32m    825\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_kwargs,\n\u001b[1;32m    827\u001b[0m     )\n\u001b[0;32m--> 828\u001b[0m \u001b[43mls_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/utils.py:156\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mHTTPError\u001b[0m: [Errno 401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Invalid token\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLangSmithAuthError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Create the dataset and examples in LangSmith\u001b[39;00m\n\u001b[1;32m     90\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome_tax_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 91\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m client\u001b[38;5;241m.\u001b[39mcreate_examples(\n\u001b[1;32m     93\u001b[0m     dataset_id\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     94\u001b[0m     examples\u001b[38;5;241m=\u001b[39mexamples\n\u001b[1;32m     95\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/client.py:3417\u001b[0m, in \u001b[0;36mClient.create_dataset\u001b[0;34m(self, dataset_name, description, data_type, inputs_schema, outputs_schema, transformations, metadata)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3415\u001b[0m     dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs_schema_definition\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m outputs_schema\n\u001b[0;32m-> 3417\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3418\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3419\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/datasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_orjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3423\u001b[0m ls_utils\u001b[38;5;241m.\u001b[39mraise_for_status_with_text(response)\n\u001b[1;32m   3425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas\u001b[38;5;241m.\u001b[39mDataset(\n\u001b[1;32m   3426\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[1;32m   3427\u001b[0m     _host_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host_url,\n\u001b[1;32m   3428\u001b[0m     _tenant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_optional_tenant_id(),\n\u001b[1;32m   3429\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/client.py:863\u001b[0m, in \u001b[0;36mClient.request_with_retries\u001b[0;34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithRateLimitError(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRate limit exceeded for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    861\u001b[0m     )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithAuthError(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthentication failed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m     )\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithNotFoundError(\n\u001b[1;32m    869\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m     )\n",
      "\u001b[0;31mLangSmithAuthError\u001b[0m: Authentication failed for /datasets. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Invalid token\"}')"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define the examples for the dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"제1조에 따른 소득세법의 목적은 무엇인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"소득세법의 목적은 소득의 성격과 납세자의 부담능력에 따라 적정하게 과세함으로써 조세부담의 형평을 도모하고 재정수입의 원활한 조달에 이바지하는 것입니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"'거주자'는 소득세법에서 어떻게 정의되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"'거주자'는 한국에 주소를 두거나 183일 이상 거소를 둔 개인을 의미합니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"'비거주자'는 소득세법에 따라 어떻게 정의되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"'비거주자'는 거주자가 아닌 개인을 의미합니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"소득세법에 따른 '내국법인'은 누구를 의미하나요?\"},\n",
    "        \"outputs\": {\"answer\": \"'내국법인'은 법인세법 제2조 제1호에 따른 내국법인을 의미합니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"소득세법에 따라 소득세를 납부할 의무가 있는 사람은 누구인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"거주자 및 국내원천소득이 있는 비거주자는 소득세를 납부할 의무가 있습니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"거주자의 과세 범위는 무엇인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"거주자는 법에서 규정한 모든 소득에 대해 과세되며, 비거주자는 국내원천소득에 대해서만 과세됩니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"소득세법에 따라 소득은 어떻게 분류되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"소득은 종합소득, 퇴직소득, 양도소득으로 분류됩니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"종합소득이란 무엇인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"종합소득은 이자소득, 배당소득, 사업소득, 근로소득, 연금소득 및 기타소득을 포함합니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"세금이 면제되는 소득의 종류는 무엇인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"비과세 소득에는 공익신탁의 이익, 특정 사업소득 및 기타 법에서 정한 특정 소득이 포함됩니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"소득세의 과세기간은 어떻게 되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"소득세의 과세기간은 매년 1월 1일부터 12월 31일까지입니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"거주자의 소득세 납세지는 주소지이며, 주소지가 없으면 거소지입니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"비거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"비거주자의 소득세 납세지는 국내사업장의 소재지입니다. 국내사업장이 여러 곳인 경우 주된 사업장의 소재지가 납세지가 됩니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"납세지가 불분명한 경우 어떻게 되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"납세지가 불분명한 경우 대통령령으로 정합니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"원천징수세액의 납세지는 어떻게 결정되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"원천징수세액의 납세지는 원천징수자의 종류와 위치에 따라 결정됩니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"납세자의 사망 시 납세지는 어떻게 되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"납세자의 사망 시 상속인 또는 납세관리인의 주소지나 거소지가 납세지가 됩니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"신탁 소득에 대한 납세의 범위는 무엇인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"신탁 소득에 대한 납세의 범위는 신탁의 수익자가 해당 소득에 대해 납세의무를 집니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"원천징수 대상 소득은 무엇인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"이자소득, 배당소득 및 기타 법에서 정한 소득은 원천징수 대상입니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"공동 소유 자산의 양도소득은 어떻게 과세되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"공동 소유 자산의 양도소득은 각 거주자 소유 지분에 따라 과세됩니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"이자 소득의 출처는 무엇인가요?\"},\n",
    "        \"outputs\": {\"answer\": \"이자 소득의 출처는 정부 및 지방자치단체가 발행한 채권, 법인이 발행한 채권, 국내외 은행 예금 등입니다.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"소득세법에서 배당소득은 어떻게 정의되나요?\"},\n",
    "        \"outputs\": {\"answer\": \"배당소득은 국내외 법인으로부터 받는 배당금 및 배분금, 기타 법에서 정한 소득을 포함합니다.\"},\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create the dataset and examples in LangSmith\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retriever 생성\n",
    "\n",
    "- Evaluation을 위한 Retriever 생성\n",
    "- 3.x 에서 생성한 Pinecone Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = UpstageEmbeddings(model=\"solar-embedding-1-large\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = 'table-markdown-index'\n",
    "\n",
    "database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)\n",
    "retriever = database.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LLM 답변 생성을 위한 RagBot \n",
    "\n",
    "- retriever와 OpenAI API를 활용한 RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG bot\n",
    "\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"gpt-4o\"):\n",
    "        # 위에서 선언한 retriever를 할용해서 Retrieval 실행\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        # LangSmith 문법\n",
    "        self._client = wrap_openai(openai.Client())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def invoke_llm(self, question, docs):\n",
    "        # `retrieve_docs()` 를 통해 가져온 문서들을 system prompt로 전달\n",
    "        # 3.3에서 했던 방식과 유사함\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"당신은 한국의 소득세 전문가입니다.\"\n",
    "                    \"아래 소득세법을 참고해서 사용자의 질문에 답변해주세요.\\n\\n\"\n",
    "                    f\"## 소득세법\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluators 를 활용해서 `answer`와 `context`를 평가할 예정\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in docs],\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rag_answer(example: dict):\n",
    "    \"\"\"답변만 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"]}\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Context를 활용해서 hallucination을 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "# Grade prompt\n",
    "# 답변의 정확도를 측정하기위해 사용되는 프롬프트\n",
    "grade_prompt_answer_accuracy = prompt = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    RAG 답변 성능을 측정하기 위한 evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # `example`이 데이터를 생성할 때 입력한 `Question-Answer` pair. `run`은 `RagBot`을 활용해서 생성한 LLM의 답변\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    reference = example.outputs[\"output_answer\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatUpstage()\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"correct_answer\": reference,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Grade prompt\n",
    "# 답변이 사용자의 질문에 얼마나 도움되는지 판단하는 프롬프트\n",
    "grade_prompt_answer_helpfulness = prompt = hub.pull(\"langchain-ai/rag-answer-helpfulness\")\n",
    "\n",
    "def answer_helpfulness_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    답변이 사용자의 질문에 얼마나 도움되는지 판단하는 Evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # 데이터셋의 답변과 비교하지 않고, 데이터셋의 질문에 대한 LLM의 답변의 가치를 평가함\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatUpstage()\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_answer_helpfulness | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_helpfulness_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhlee/.pyenv/versions/3.10.17/envs/streamlit/lib/python3.10/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "# hallucination 판단을 위한 프롬프트\n",
    "grade_prompt_hallucinations = prompt = hub.pull(\"langchain-ai/rag-answer-hallucination\")\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    hallucination 판단을 위한 Evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # 데이터셋에 있는 질문과, LLM이 답변을 생성할 때 사용한 context를 활용\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "\n",
    "    # LLM의 답변\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatUpstage()\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_hallucinations | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"documents\": contexts,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RunEvaluator() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangsmith\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunEvaluator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# RunEvaluator 초기화\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mRunEvaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 사용할 모델 지정\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mincome_tax_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 평가에 사용할 데이터셋 이름\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhelpfulness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhallucination\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 실행할 평가 항목\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mincome tax v1, gpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 메타데이터 추가\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 평가 실행\u001b[39;00m\n\u001b[1;32m     12\u001b[0m experiment_results \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m     13\u001b[0m     predict_function\u001b[38;5;241m=\u001b[39mpredict_rag_answer_with_context,  \u001b[38;5;66;03m# 평가에 사용할 함수\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     experiment_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minflearn-evaluator-lecture-hallucination\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 실험 이름\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: RunEvaluator() takes no arguments"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import RunEvaluator\n",
    "\n",
    "# RunEvaluator 초기화\n",
    "evaluator = RunEvaluator(\n",
    "    model=\"gpt-4o\",  # 사용할 모델 지정\n",
    "    dataset=\"income_tax_dataset\",  # 평가에 사용할 데이터셋 이름\n",
    "    evaluators=[\"accuracy\", \"helpfulness\", \"hallucination\"],  # 실행할 평가 항목\n",
    "    metadata={\"version\": \"income tax v1, gpt-4o\"}  # 메타데이터 추가\n",
    ")\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluator.evaluate(\n",
    "    predict_function=predict_rag_answer_with_context,  # 평가에 사용할 함수\n",
    "    experiment_prefix=\"inflearn-evaluator-lecture-hallucination\"  # 실험 이름\n",
    ")\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(\"Evaluation Results:\", experiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
